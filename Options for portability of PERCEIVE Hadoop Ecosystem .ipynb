{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "To address options for portability of PERCEIVE Hadoop Ecosystem and apply big data technology for PERCEIVE project, this notebook aims to build an Apache Nifi + Kite sdk + Apache Spark pipeline, and show the potential value and usage of this data pipeline.\n",
    "\n",
    "This article is consisted of three parts. For the first part, we will setup the environment and relevant components, and build dependency between each component. The second part will show a simple Nifi data flow from local and the web to HDFS that demonstrates several fundamental capabilities of Nifi, including:\n",
    "\n",
    "\n",
    "**(need to list the capabilities of nifi from the end example)**\n",
    "\n",
    "The third part will address the advantage of Nifi and show why the pipeline can potentially contribute to PERCEIVE project in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Before moving to next part, here is a brief introduction about Apache Nifi and Kite sdk.\n",
    "\n",
    "a. Apache NiFi:\n",
    "\n",
    "Nifi is an easy to use, powerful, and reliable dataflow tool that enables the automation of data flow between systems.Some of the use cases include, but are not limited to:\n",
    "\n",
    "- **Big Data Ingest**– Offers a simple, reliable and secure way to collect data streams.\n",
    "- **IoAT Optimization**– Allows organizations to overcome real world constraints such as limited or expensive bandwidth while ensuring data quality and reliability.\n",
    "- **Compliance**– Enables organizations to understand everything that happens to data in motion from its creation to its final resting place, which is particularly important for regulated industries that must retain and report on chain of custody.\n",
    "- **Digital Security**– Helps organizations collect large volumes of data from many sources and prioritize which data is brought back for analysis first, a critical capability given the time sensitivity of identifying security breaches\n",
    "\n",
    "![egauge_portfolio](img/nifi_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Apache Kite sdk:\n",
    "\n",
    "From the official website of kite sdk, Kite is a high-level data layer for Hadoop, which provides a high-level API working with Hive, Oozie, HDFS and HBase. Using Kite, it is much convenient to maintain datasets and relevant metadata through Avro schema. \n",
    "\n",
    "Although most jobs are implemented through the Kite Command Line Interface, Nifi provides the following kite processors that realize the Kite function: ConvertAvroSchema, ConvertCSVToAvro, ConvertJSONToAvro, InferAvroSchema, StoreInKiteDataset.\n",
    "\n",
    "Here is the example of a schema:\n",
    "\n",
    "![egauge_portfolio](img/kite_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installation\n",
    "This tutorial was tested using the following environment and components:\n",
    "\n",
    "(Since the installation for the above components can easily be found through google, we will simply put the link here)\n",
    "\n",
    "- Ubuntu(64 bit) on VirualBox:\n",
    "    - https://linus.nci.nih.gov/bdge/installUbuntu.html\n",
    "- Apache Nifi 1.3.0:\n",
    "    - For installation: https://www.youtube.com/watch?v=ZTXRm7tqQs4\n",
    "    - User guide: https://nifi.apache.org/docs.html\n",
    "    - Required jdk environment\n",
    "- Apache Hadoop 2.8.1 + Apache Spark 2.2.0 + Scala 2.12.3:\n",
    "    - Need to change the version: https://medium.com/@ivanermilov/setting-up-hadoop-spark-hive-development-environment-on-ubuntu-94f0f8166ef1\n",
    "- Apache Kite sdk (in progress)\n",
    "    - http://kitesdk.org/docs/1.1.0/Install-Kite.html\n",
    "    - http://kitesdk.org/docs/1.0.0/Kite-SDK-Guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building the dependency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
