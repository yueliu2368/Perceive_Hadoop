{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields that function2 works: \n",
    "    Description-Summary, Attack prerequistite, methods of attack, example_instances, attack_skills_or Knowledge_required, probing_technique,Indicators-Warnings_of_Attack, Solutions_and_Mitigations, Attack_Motivation-Consequences, Injection_Vector, Payload, Activation_Zone, Payload_Activation_Impact, Related_Security_Principles, Related_Guidelines, Purposes, CIA_Impact, Technical_Context\n",
    "    \n",
    "    \n",
    "The fields that function1 works:\n",
    "    Typical_Severity\n",
    "\n",
    "\n",
    "如果field_entry 有多个，并且每一个都一样； 里面的元素都只有一个，则可以合并到一个cell里\n",
    "    Attack_Prerequisites\n",
    "    \n",
    "如果field_entry 有多个，并且不一样，则可以 以一行的形式输出\n",
    "\n",
    "如果field——entry有多个，并且都一样， 里面的元素不仅仅只有text，则需要以多行的形式来输出\n",
    "\n",
    "只有一个field entry， text都多个 则可以合并到一个cell里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = lxml.etree.XMLParser(remove_comments=False)\n",
    "tree = lxml.etree.parse('capec_v2.11.xml',parser=parser)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Remove namespaces from XML.  \n",
    "for elem in root.getiterator(): \n",
    "    if not hasattr(elem.tag, 'find'): continue  # (1)\n",
    "    i = elem.tag.find('}') # Counts the number of characters up to the '}' at the end of the XML namespace within the XML tag\n",
    "    if i >= 0: \n",
    "        elem.tag = elem.tag[i+1:] # Starts the tag a character after the '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_dict_to_csv(output_file,csv_header,dict_data):\n",
    "    '''\n",
    "    Create a CSV file with headers and write a dictionary;\n",
    "    If the file already existes, only append a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        output_file -- name of the output csv file\n",
    "        csv_header -- the header of the output csv file. \n",
    "        dict_data -- the dictionary that will be writen into the CSV file. The number of \n",
    "                     element in the dictionary should be equal to or lower than the number of\n",
    "                     headers of the CSV file. \n",
    "    \n",
    "    Outcome:\n",
    "        a new csv file with headers and one row that includes the information from the dictionary;\n",
    "        or an existing CSV file with a new row that includes the information from the dictionary\n",
    "    '''\n",
    "    # create a file if the file does not exist; if exsits, open the file\n",
    "    with open(output_file, 'a',encoding='UTF-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_header,lineterminator='\\n')\n",
    "        \n",
    "        # check whether the csv file is empty\n",
    "        if csv_file.tell()==0:\n",
    "            # if empty, write header and the dictionary\n",
    "            writer.writeheader()         \n",
    "            writer.writerow(dict_data)\n",
    "        else:\n",
    "            # if not empty, only write the dictionary\n",
    "            writer.writerow(dict_data)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_line_field_parser(target_field, root):\n",
    "    # define the path of target field. Here we select all element nodes that the tag is the target field\n",
    "    target_field_path='Attack_Pattern/./'+target_field\n",
    "    # extract weakness table in the XML\n",
    "    weakness_table = root[2]\n",
    "    # define the headers\n",
    "    output_header=['capec_id','field']\n",
    "    # define path of the output file\n",
    "    output_path=target_field+'.csv'\n",
    "    \n",
    "    \n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        # check whether there is no content under target field:\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "        # extract cwe_id from the attribute of its parent node\n",
    "        capec_id=field.getparent().attrib.get('ID')\n",
    "        \n",
    "        # the dictionary that will be written to a CSV file\n",
    "        field_dict=dict()\n",
    "        field_dict['capec_id']=capec_id\n",
    "        field_dict['field']=target_field\n",
    "        field_content=''\n",
    "        \n",
    "        # for each field entry node under the target field node\n",
    "        for field_entry in list(field):\n",
    "            \n",
    "            field_entry_tag=field_entry.tag\n",
    "            field_entry_content=field_entry.text\n",
    "            \n",
    "            ### 1.1\n",
    "            if type(field_entry_content)==type(None):\n",
    "                if field_entry_tag.lower() not in output_header:\n",
    "                    output_header.append(field_entry_tag.lower())\n",
    "            ### 1.2\n",
    "            # if there is no node under field_entry\n",
    "            elif not field_entry_content.isspace():\n",
    "                if field_entry.tag.lower()=='text':\n",
    "                    field_entry.tag=target_field\n",
    "                \n",
    "                if field_entry_tag.lower() not in output_header:\n",
    "                    output_header.append(field_entry_tag.lower())\n",
    "                          \n",
    "                #if there are multiple entry_element entries using a same tag, all content will be concatenated\n",
    "                if field_entry_tag.lower() in field_dict:\n",
    "                    # add the concatenated content into the dictionary \n",
    "                    field_dict[field_entry_tag.lower()]=field_dict[field_entry_tag.lower()]+ ';'+field_entry_content\n",
    "                \n",
    "                # if not, directly add the entry_element content into the dictionary\n",
    "                else:\n",
    "                    field_dict[field_entry_tag.lower()]=field_entry_content\n",
    "                    \n",
    "            ### 2       \n",
    "            # check whether there is node under field_entry:\n",
    "            elif field_entry_content.isspace():\n",
    "                \n",
    "                # traverse all entry_element nodes under each field entry\n",
    "                for entry_element in list(field_entry):\n",
    "                    # generate tag and content of each entry_element\n",
    "                    entry_element_tag=entry_element.tag\n",
    "                    entry_element_content=entry_element.text\n",
    "\n",
    "                    field_element_header=field_entry_tag+'_'+entry_element_tag\n",
    "                    if field_element_header.lower() not in output_header:\n",
    "                        output_header.append(field_element_header.lower())\n",
    "                    \n",
    "                    if type(entry_element_content)==type(None):\n",
    "                            continue\n",
    "                            \n",
    "                    # check whether there is one more element under entry_element \n",
    "                    if not entry_element_content.isspace():\n",
    "                        field_content=field_content+' '+entry_element_content\n",
    "                    else:\n",
    "                        for entry_element_child in list(entry_element):\n",
    "                            entry_element_child_content=entry_element_child.text\n",
    "                            field_content=field_content+' '+entry_element_child_content\n",
    "\n",
    "                field_dict[field_element_header.lower()]=field_content\n",
    "        # write the dictionary with headers to a CSV file\n",
    "        print(field_dict)\n",
    "        write_dict_to_csv(output_path,output_header,field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_lines_field_parser(target_field, root):\n",
    "    # define the path of target field. Here we select all element nodes that the tag is the target field\n",
    "    target_field_path='Attack_Pattern/./'+target_field\n",
    "    # extract attack pattern table in the XML\n",
    "    attack_patern_table = root[2]\n",
    "    # define the headers\n",
    "    output_header=['capec_id','field']\n",
    "    # define path of the output file\n",
    "    output_path=target_field+'.csv'\n",
    "    \n",
    "    ##### 1\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "        # for each field entry, in case there are multiple field entries under the target field node\n",
    "        for field_entry in list(field):\n",
    "            # traverse all entry_element nodes under each field entry\n",
    "            for entry_element in list(field_entry):\n",
    "                # generate tag and each entry_element\n",
    "                entry_element_tag=entry_element.tag\n",
    "                entry_element_content=entry_element.text\n",
    "                \n",
    "                # check whether there is one more element under entry_element\n",
    "                if entry_element_content.isspace():\n",
    "                    for entry_element_child in list(entry_element):\n",
    "                        entry_element_child_tag=entry_element_child.tag\n",
    "                        entry_element_child_content=entry_element_child.text\n",
    "                        \n",
    "                        # check wehther there is one more element under entry_element_child\n",
    "                        if entry_element_child_content.isspace():\n",
    "                            for entry_element_child_embed in list(entry_element_child):\n",
    "                                entry_element_child_embed_tag=entry_element_child_embed.tag\n",
    "                                field_entry_header=entry_element_child_tag+'_'+entry_element_child_embed_tag\n",
    "                                if field_entry_header.lower() not in output_header:\n",
    "                                    output_header.append(field_entry_header.lower())\n",
    "\n",
    "                        else:\n",
    "                            field_entry_header=entry_element_tag+'_'+entry_element_child_tag\n",
    "                            # append the tag to the output_header list if it does not exist in the list\n",
    "                            if field_entry_header.lower() not in output_header:\n",
    "                                output_header.append(field_entry_header.lower())\n",
    "                    \n",
    "                else:\n",
    "                    # append the tag to the output_header list if it does not exist in the list\n",
    "                    if entry_element_tag.lower() not in output_header:\n",
    "                        output_header.append(entry_element_tag.lower())\n",
    "    \n",
    "    #### 2\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "        # extract cwe_id from the attribute of its parent node\n",
    "        capec_id=field.getparent().attrib.get('ID')\n",
    "        \n",
    "        # for each field entry, in case there are multiple field entries under the target field node\n",
    "        for field_entry in list(field):\n",
    "            \n",
    "            field_entry_dict=dict()\n",
    "            field_entry_dict['capec_id']=capec_id\n",
    "            field_entry_dict['field']=target_field\n",
    "            # traverse all entry_element nodes under each field entry\n",
    "            for entry_element in list(field_entry):\n",
    "                # generate tag and each entry_element\n",
    "                entry_element_tag=entry_element.tag\n",
    "                entry_element_content=entry_element.text\n",
    "                \n",
    "                # check whether there is one more lement under field\n",
    "                if entry_element_content.isspace():\n",
    "                    for entry_element_child in list(entry_element):\n",
    "                        entry_element_child_tag=entry_element_child.tag\n",
    "                        entry_element_child_content=entry_element_child.text\n",
    "                        field_entry_header=entry_element_tag+'_'+entry_element_child_tag\n",
    "                    \n",
    "                        # check wehther there is one more element under entry_element_child\n",
    "                        if entry_element_child_content.isspace():\n",
    "                            for entry_element_child_embed in list(entry_element_child):\n",
    "                                entry_element_child_embed_tag=entry_element_child_embed.tag\n",
    "                                entry_element_child_embed_content=entry_element_child_embed.text\n",
    "                                if type(entry_element_child_embed_content)==type(None):\n",
    "                                    continue\n",
    "                                field_entry_header=entry_element_child_tag+'_'+entry_element_child_embed_tag\n",
    "\n",
    "                                if field_entry_header.lower() in field_entry_dict:\n",
    "                                # add the concatenated content into the dictionary \n",
    "                                    field_entry_dict[field_entry_header.lower()]=field_entry_dict[field_entry_header.lower()]+ ';'+ entry_element_child_embed_content\n",
    "                                # if not, directly add the entry_element content into the dictionary\n",
    "                                else:\n",
    "                                    field_entry_dict[field_entry_header.lower()]= entry_element_child_embed_content\n",
    "\n",
    "                        else:\n",
    "                            field_entry_header=entry_element_tag+'_'+entry_element_child_tag                            \n",
    "                            # content:\n",
    "                            if field_entry_header.lower() in field_entry_dict:\n",
    "                            # add the concatenated content into the dictionary \n",
    "                                field_entry_dict[field_entry_header.lower()]=field_entry_dict[field_entry_header.lower()]+ ';'+ entry_element_child_content\n",
    "                            # if not, directly add the entry_element content into the dictionary\n",
    "                            else:\n",
    "                                field_entry_dict[field_entry_header.lower()]= entry_element_child_content\n",
    "                    \n",
    "                else:\n",
    "                    # content:\n",
    "                    if entry_element_tag.lower() in field_entry_dict:\n",
    "                    # add the concatenated content into the dictionary \n",
    "                        field_entry_dict[entry_element_tag.lower()]=field_entry_dict[entry_element_tag.lower()]+ ';'+entry_element_content\n",
    "                    # if not, directly add the entry_element content into the dictionary\n",
    "                    else:\n",
    "                        field_entry_dict[entry_element_tag.lower()]=entry_element_content\n",
    "\n",
    "            # write the dictionary with headers to a CSV file    \n",
    "            write_dict_to_csv(output_path,output_header,field_entry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cython_function_or_method' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-b51f472ee285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Typical_Likelihood_of_Exploit'\u001b[0m \u001b[1;31m# not work 多个不同tag 的field_entry 下面直接就是text    ？\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmulti_lines_field_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-243-609af111cd50>\u001b[0m in \u001b[0;36mmulti_lines_field_parser\u001b[1;34m(target_field, root)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                     \u001b[1;31m# append the tag to the output_header list if it does not exist in the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mentry_element_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_header\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                         \u001b[0moutput_header\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry_element_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cython_function_or_method' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "### single_line_fields_parser:\n",
    "a='Attack_Prerequisites' #ok work 0   header=attack_prerequisite_text\n",
    "rsr='Relevant_Security_Requirements' # ok work 0  header=relevant_security_requirement_text\n",
    "rsp='Related_Security_Principles' # ok work0   header=related_security_principle_text\n",
    "rg='Related_Guidelines' #ok work0 header=related_guideline_text\n",
    "s='Solutions_and_Mitigations' # ok work 0  header=solution_or_mitigation_text\n",
    "############################\n",
    "p='Probing_Techniques' #  work  element下面还有一个层级   修改0   header=probing_technique_description\n",
    "iw='Indicators-Warnings_of_Attack' # work element 下面还有一个层级 修改0  header= indicator-warning_of_attack_description\n",
    "\n",
    "####################\n",
    "#都拥有一个或者多个field entry，但是每一个field entry下面没有接下来的层级，内容直接保存在field——entry\n",
    "\n",
    "m='Methods_of_Attack' # work 和t是一种类型     1  header=method_of_attack\n",
    "r='Resources_Required' # work, 只有field_entry 一个层级  1 header=resources_required\n",
    "pur='Purposes' #work  1  header=purpose\n",
    "c='CIA_Impact' # work 1 header= confidentiality_impact\tintegrity_impact\tavailability_impact\n",
    "\n",
    "\n",
    "############################  multi_lines_fields_parser\n",
    "at='Attacker_Skills_or_Knowledge_Required' # work 2  \n",
    "amc='Attack_Motivation-Consequences' # work     2 \\\n",
    "e='Examples-Instances' #  work  但是有一些地方有问题\n",
    "\n",
    "\n",
    "########### ？ 没准可以用0\n",
    "tc='Technical_Context'  # not work  有多个不一样的field——entry  3\n",
    "rf='References' # not work  3\n",
    "ch='Content_History' # not work 有多个不一样的field_entry 3\n",
    "\n",
    "#############\n",
    "t='Typical_Likelihood_of_Exploit' # not work 多个不同tag 的field_entry 下面直接就是text    ？   \n",
    "\n",
    "single_line_field_parser(tc,root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
